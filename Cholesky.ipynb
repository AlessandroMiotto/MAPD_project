{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c09336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLUSTER DEPLOYMENT, TO BE EXECUTED ONLY IN A LOCAL ENVIRONMENT!!\n",
    "from dask.distributed import Client, LocalCluster\n",
    "\n",
    "# For now, local deployment on my computer (multicore)\n",
    "ncore = 4\n",
    "cluster = LocalCluster(n_workers=ncore, threads_per_worker=1)\n",
    "client = Client(cluster)\n",
    "\n",
    "# Print the dashboard link over the port 8787\n",
    "print(client.dashboard_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2654bbe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLUSTER DEPLOYMENT ON CLOUDVENETO\n",
    "from dask.distributed import Client, SSHCluster\n",
    "\n",
    "cluster = SSHCluster(\n",
    "    [\"10.67.22.154\", \"10.67.22.216\", \"10.67.22.116\", \"10.67.22.113\"],\n",
    "    connect_options={\"known_hosts\": None},\n",
    "    scheduler_options={\"port\": 8786, \"dashboard_address\": \":8797\"}\n",
    ")\n",
    "\n",
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8c5194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if everything went smoothly\n",
    "print(client)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eee55fb",
   "metadata": {},
   "source": [
    "Import the necessary stuff along with the California housing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7495557",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.array as da\n",
    "import dask\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "# Download California Housing dataset\n",
    "data = fetch_california_housing(as_frame=True)\n",
    "\n",
    "# Convert features into Dask Array (it's a matrix). N partition = 16\n",
    "n_partition = 4        # number of partition in memory\n",
    "length_partition = data.data.shape[0] // n_partition\n",
    "X_da = da.from_array(data.data.values, chunks=(length_partition, data.data.shape[1]))\n",
    "\n",
    "print(\"Number of Dask partitions:\",  X_da.npartitions) \n",
    "print(\"Length of each partition:\", length_partition, \"rows\")\n",
    "print(\"Length of the whole dataset:\", data.data.shape[0], \"rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17254d35",
   "metadata": {},
   "source": [
    "Now we'll define the parallel and serial algorithm for the Cholesky QR decomposition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a795cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_choleskyQR_parallel(X_da : dask.array.Array):\n",
    "    # A list of delayed tasks for each partition of the dataset\n",
    "    # Each partition computes the local Gram matrix\n",
    "    chunks_delayed = [dask.delayed(lambda x : x.T @ x)(chunk) for chunk in X_da.to_delayed().ravel()]\n",
    "\n",
    "    # Now sum all the local Gram matrices to get the global Gram matrix\n",
    "    Gram_global_delayed = dask.delayed(sum)(chunks_delayed)   ## !! This is not strictly parallel, meaning that a single worker will perform the sum instead of a tree-like operation. This is ok here, I guess, since we only have 8 chunks that need to be summed up\n",
    "\n",
    "    # Compute R as the Cholesky decomposition on the global Gram matrix (as a delayed even if a serial operation just call .compute at the end)\n",
    "    R = dask.delayed(np.linalg.cholesky)(Gram_global_delayed)\n",
    "    #R.visualize(\"fig/CholeskyR.png\")\n",
    "    R = R.compute() # Compute R. This will put a stop at the parallel operation\n",
    "    R_inv = np.linalg.inv(R) # It's a small matrix, so this operation is fast even if serial\n",
    "\n",
    "    Q = X_da.map_blocks(lambda block: block @ R_inv, dtype=X_da.dtype)\n",
    "    #Q.visualize(\"fig/CholeskyQ.png\")\n",
    "    Q = Q.compute() # Compute Q\n",
    "    return Q, R\n",
    "\n",
    "def compute_choleskyQR_serial(X):\n",
    "    # Global gram matrix\n",
    "    G = X.T @ X\n",
    "    R = np.linalg.cholesky(G)\n",
    "    R_inv = np.linalg.inv(R)\n",
    "    Q = X @ R_inv\n",
    "    \n",
    "    return Q, R\n",
    "\n",
    "def compute_choleskyR_parallel(X_da : dask.array.Array):\n",
    "    # A list of delayed tasks for each partition of the dataset\n",
    "    # Each partition computes the local Gram matrix\n",
    "    chunks_delayed = [dask.delayed(lambda x : x.T @ x)(chunk) for chunk in X_da.to_delayed().ravel()]\n",
    "    # Now sum all the local Gram matrices to get the global Gram matrix\n",
    "    Gram_global_delayed = dask.delayed(sum)(chunks_delayed)\n",
    "    # Compute R as the Cholesky decomposition on the global Gram matrix (as a delayed even if a serial operation just call .compute at the end)\n",
    "    R = dask.delayed(np.linalg.cholesky)(Gram_global_delayed)\n",
    "    R = R.compute() # Compute R\n",
    "    return  R\n",
    "\n",
    "def compute_choleskyR_serial(X):\n",
    "    # Global gram matrix\n",
    "    G = X.T @ X\n",
    "    R = np.linalg.cholesky(G)\n",
    "    return R"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1abb0291",
   "metadata": {},
   "source": [
    "Let's measure the time it takes to perform the Cholesky QR decomposition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a094b150",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# parallel\n",
    "Q_p, R_p = compute_choleskyQR_parallel(X_da)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ccd279",
   "metadata": {},
   "source": [
    "The measured wall time is smaller than the total (cpu+system) time, meaning that the program went parallel (and in fact, the ratio wall / total should converge to n_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e57eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# serial\n",
    "Q_s, R_s = compute_choleskyQR_serial(data.data.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad19947e",
   "metadata": {},
   "source": [
    "Here again, wall time is smaller than total time. This is because even when using serial Numpy function, under the hood the BLAS implementation of certain algorithm leverages multithreading\n",
    "\n",
    "However, the serial algorithm is faster than the parallel one. This is probably because the California dataset is not that big (only $20k$ rows, easily fittable in the RAM). As of now, we still can't see a real speedup\n",
    "\n",
    "Cholesky QR is sadly known to be unstable. In fact:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50244094",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see whether the results are compatible\n",
    "diffR = np.linalg.norm(R_p - R_s, 2)\n",
    "diffQ = np.linalg.norm(Q_p - Q_s, 2)\n",
    "print(f\"||R_parallel - R_serial||_2 = {diffR}\")\n",
    "print(f\"||Q_parallel - Q_serial||_2 = {diffQ}\")\n",
    "\n",
    "# Check orthogonality of Q\n",
    "orthogonality_metric = np.linalg.norm(Q_s.T @ Q_s - np.eye(Q_s.shape[1]), 2)\n",
    "print(f\"||Q^T @ Q- I||_2 = {orthogonality_metric}\")\n",
    "# Check decomposition\n",
    "decomp_metric = np.linalg.norm(data.data.values - Q_s @ R_s, 2)\n",
    "print(f\"||X - Q @ R||_2 = {decomp_metric}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8f3404",
   "metadata": {},
   "source": [
    "As expected, the decomposition yielded a non reasonnable result (Q is not orthogonal, the algorithm is highly unstable)\n",
    "\n",
    "\n",
    "Let's try with a different and larger dataset (HIGGS dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75bdb666",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "\n",
    "# A huge dataset\n",
    "df = dd.read_csv(\"HIGGS.csv\", header=None, blocksize=\"400MB\")\n",
    "X_df = df.iloc[:, 1:] \n",
    "X_da = X_df.to_dask_array(lengths=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06face3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "Q, R = compute_choleskyQR_parallel(X_da)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envLabComp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
